# @package _global_

defaults:
  - /habitat: habitat_config_base
  - /habitat/task: task_config_base

  - /habitat/simulator/agents/habitat_mas_agents@habitat.simulator.agents.agent_0: FetchRobot_default
  - /habitat/simulator/agents/habitat_mas_agents@habitat.simulator.agents.agent_1: FetchRobot_default

  # - /habitat/dataset/rearrangement: hssd
  - /habitat/dataset/embodied_mas: dataset_manipulation

  - /habitat/task/actions@habitat.task.actions.agent_0_arm_pick_action: arm_pick_action
  - /habitat/task/actions@habitat.task.actions.agent_0_arm_place_action: arm_place_action
  - /habitat/task/actions@habitat.task.actions.agent_0_base_velocity: base_velocity_non_cylinder
  - /habitat/task/actions@habitat.task.actions.agent_0_rearrange_stop: rearrange_stop
  - /habitat/task/actions@habitat.task.actions.agent_0_pddl_apply_action: pddl_apply_action
  - /habitat/task/actions@habitat.task.actions.agent_0_oracle_nav_action: fetch_oracle_nav_action
  - /habitat/task/actions@habitat.task.actions.agent_0_arm_reset_action: arm_reset_action
  - /habitat/task/actions@habitat.task.actions.agent_0_oracle_nav_coord_action: oracle_nav_coord_action
  - /habitat/task/actions@habitat.task.actions.agent_0_wait: wait

  - /habitat/task/actions@habitat.task.actions.agent_1_arm_pick_action: arm_pick_action
  - /habitat/task/actions@habitat.task.actions.agent_1_arm_place_action: arm_place_action
  - /habitat/task/actions@habitat.task.actions.agent_1_base_velocity: base_velocity_non_cylinder
  - /habitat/task/actions@habitat.task.actions.agent_1_rearrange_stop: rearrange_stop
  - /habitat/task/actions@habitat.task.actions.agent_1_pddl_apply_action: pddl_apply_action
  - /habitat/task/actions@habitat.task.actions.agent_1_oracle_nav_action: fetch_oracle_nav_action
  - /habitat/task/actions@habitat.task.actions.agent_1_arm_reset_action: arm_reset_action
  - /habitat/task/actions@habitat.task.actions.agent_1_oracle_nav_coord_action: oracle_nav_coord_action
  - /habitat/task/actions@habitat.task.actions.agent_1_wait: wait


  - /habitat/task/measurements:
    - pddl_success
    - num_steps
    - did_agents_collide
    - num_agents_collide
    - composite_stage_goals
    - pddl_subgoal_reward
    - rearrange_cooperate_reward
    - object_to_goal_distance
  - /habitat/task/lab_sensors:
    - relative_resting_pos_sensor
    - target_start_sensor
    - target_goal_gps_compass_sensor
    - goal_sensor
    - joint_sensor
    - is_holding_sensor
    - end_effector_sensor
    # - target_start_gps_compass_sensor
    # - target_goal_gps_compass_sensor
    - localization_sensor
    # - detected_objects_sensor
    # - trans_of_robot
    # - obj_list_infomation
    # - arm_workspace_rgb_sensor
    - camera_info
    - camera_extrinsic_info
    # - navtemptran_s
    # - get_nav_goal_point
    # - target_point
    # - nav_workspace_rgb_sensor
    # - nav_workspace_points_sensor
    # - arm_workspace_rgb_sensor
    - obj_bbox_sensor
    - target_bbox_sensor
    - rec_bbox_sensor
    - object_to_goal_distance_sensor
    # - depth_get
    - pddl_text_goal
    # - object_sensor
    - has_finished_oracle_nav
    # - arm_workspace_points_sensor
    # - has_finished_arm_action
    # - depth_rot_get
    # - depth_trans_get
  - /habitat/task/lab_sensors@habitat.task.lab_sensors.agent_0_agents_within_threshold: agents_within_threshold
  - /habitat/task/lab_sensors@habitat.task.lab_sensors.agent_1_agents_within_threshold: agents_within_threshold
  - _self_

habitat:
  # seed: 42
  task:
    lab_sensors:
      agent_0_agents_within_threshold:
        x_len: 2.0
        y_len: 1.5
        agent_idx: 0
      agent_1_agents_within_threshold:
        x_len: 2.0
        y_len: 1.5
        agent_idx: 1
    type: RearrangePddlTask-v0
    reward_measure: rearrange_cooperate_reward
    success_measure: pddl_success
    success_reward: 10.0
    min_distance_start_agents: 5.0
    slack_reward: -0.0005
    end_on_success: True
    constraint_violation_ends_episode: False
    constraint_violation_drops_object: True
    measurements:
      pddl_success:
        must_call_stop: False
      rearrange_cooperate_reward:
        stage_sparse_reward: 5.0
        end_on_collide: False
        collide_penalty: 0.5
    task_spec_base_path: benchmark/multi_agent/
    task_spec: pddl/pddl_fetch_stretch_rearrange
    pddl_domain_def: fp
    # actions:
    #   agent_0_base_velocity:
    #     lin_speed: 40.0
    #     ang_speed: 20.0

    #   agent_1_base_velocity:
    #     lin_speed: 40.0
    #     ang_speed: 20.0

    robot_at_thresh: 1.0

  environment:
    max_episode_steps: 600
    # iterator_options:
    #   shuffle: True
  simulator:
    type: RearrangeSim-v0
    seed: 150
    additional_object_paths:
      - "data/objects/ycb/configs/"
      - "data/objects/amazon_berkeley/configs/"
      - "data/objects/google_object_dataset/configs/"
    concur_render: True
    auto_sleep: True
    agents_order:
      - agent_0
      - agent_1

    kinematic_mode: True
    ac_freq_ratio: 1
    step_physics: False

    habitat_sim_v0:
      allow_sliding: True
      enable_physics: True
    agents:
      agent_0:
        joint_start_noise: 0.0
  dataset:
    data_path: data/datasets/policy_test/policy.json.gz
    # new
    randomize_agent_start: 1
    robot_config: data/robots/json/manipulation.json
    mode: manipulation
